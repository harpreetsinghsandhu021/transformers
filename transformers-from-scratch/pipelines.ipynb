{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "742e94f3-cfa6-4c68-8984-8110fe243c04",
   "metadata": {},
   "source": [
    "## Working with pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe637d-b735-48d8-be3d-24fcd634085e",
   "metadata": {},
   "source": [
    "The most basic object in the ðŸ¤— Transformers library is the `pipeline()` function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f280987-c2e0-43a4-bbc4-d3cf5b4c73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9336eb1-7cc5-4445-b266-e6f4ad145899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b0955a1407490d8ec0532ab9803f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525f02f6f25a4e70bfa25fcd5c6b65c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 14:31:06.894431: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-12-18 14:31:06.894508: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-12-18 14:31:06.894531: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-12-18 14:31:06.894757: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-18 14:31:06.894975: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59be0564af04262afbffda5f6399898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc83e73fedf42b1910916c9c0196c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9512071013450623}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('I`ve been looking to build a silicon valley in Punjab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0f0f7-523e-4f6d-a1b6-e5637602d289",
   "metadata": {},
   "source": [
    "We can even pass several sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359d6348-3b2c-4894-a0f9-f20c0c918c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9512071013450623},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997968077659607}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(['I`ve been looking to build a silicon valley in Punjab','Indian government is worst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb949b6d-f807-49e8-bd05-70a2e07779ea",
   "metadata": {},
   "source": [
    "By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English. The model is downloaded and cached when you create the classifier object. If you rerun the command, the cached model will be used instead and there is no need to download the model again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb365ce8-23ed-4615-9e18-e7037a01d78c",
   "metadata": {},
   "source": [
    "There are three main steps involved when you pass some text to a pipeline: \n",
    "* The text is processed into a format the model can understand\n",
    "* The preprocessed inputs are passed to the model\n",
    "* The predictions of the model are post-processed, so we can make sense of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d38da-09af-47f6-9262-cb420c9cbc27",
   "metadata": {},
   "source": [
    "#### Letâ€™s have a look at a few more Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35cf11-54cf-4c66-8eff-9c516f3d9d56",
   "metadata": {},
   "source": [
    "## Zero-shot classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1a0bc-d029-45a2-9658-d5a7a47e7300",
   "metadata": {},
   "source": [
    "Weâ€™ll start by tackling a more challenging task where we need to classify texts that havenâ€™t been labelled. This is a common scenario in real-world projects because annotating text is usually time-consuming and requires domain expertise. For this use case, the zero-shot-classification pipeline is very powerful: it allows you to specify which labels to use for the classification, so you donâ€™t have to rely on the labels of the pretrained model. Youâ€™ve already seen how the model can classify a sentence as positive or negative using those two labels â€” but it can also classify the text using any other set of labels you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e93925-3d11-4b0a-896b-59de7acfff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 2a8f12d (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b877b5549d4fb0878fb9d1acd3114b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caaa1059b524e2b8ba150f471f2fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965542ef7efe4460aa4149d1f533a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49efac8fe3264664b577bda3780cdcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c4c397a4b74d958e7f1b86be64111b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e77deae6e7437ea14399c6353faff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282de807-df16-453c-b614-e95eccc90379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I`ve been looking to build a silicon valley in Punjab.',\n",
       " 'labels': ['business', 'politics', 'education'],\n",
       " 'scores': [0.8677144050598145, 0.08291906118392944, 0.04936656355857849]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I`ve been looking to build a silicon valley in Punjab.\",\n",
    "          candidate_labels=['education', 'politics', 'business'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb216de-bc16-41db-8440-187bcce118a1",
   "metadata": {},
   "source": [
    "This pipeline is called zero-shot because you donâ€™t need to fine-tune the model on your data to use it. It can directly return probability scores for any list of labels you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db4c9f-bfa6-46ea-8a33-f7d77ec3c39a",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "The main idea here is that you provide a prompt and the model will auto-complete it by generating the remaining text. This is similar to the predictive text feature that is found on many phones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78a9eed1-ffd9-433b-8a0b-a38cdae6fd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae2f183ade5494c969307ac6bb80309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255ca8180b524bdaa51277723ea798ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00d315d93544c7aaeeadcbf6e32f8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e2f6c126f5487da943e26f6a87595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637a989151884e878c5f1a77dbda729d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9934a6c39bff4240856f4538b32fd369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f055c3f-cfdd-472b-b4fd-696e84bfbbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to write your own program by following and using common Java methods provided in the Java Language Reference Manual.\\n'}, {'generated_text': 'In this course, we will teach you how to use the basic functions of a computer to build a data storage application.\\n\\nNote that the tutorial'}, {'generated_text': 'In this course, we will teach you how to set your own alarms so that you no longer have to worry about putting it off when you open,'}]\n"
     ]
    }
   ],
   "source": [
    "# using default model\n",
    "res = generator(\"In this course, we will teach you how to\", max_length=30, num_return_sequences=3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1fdc8b9-822f-4196-86ed-fd5cb0db9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to become a successful consumer, how to create value.\\n\\n\\n\\nWhat is your next product?'}, {'generated_text': 'In this course, we will teach you how to set a specific goal. In this course, we will explore the concept of the \"goal\" so'}, {'generated_text': \"In this course, we will teach you how to get you started applying for the right to do business online, so it doesn't take a long time\"}]\n"
     ]
    }
   ],
   "source": [
    "# using distilgpt2 \n",
    "res = generator(\"In this course, we will teach you how to\", max_length=30, num_return_sequences=3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4f82d-8666-4a5b-9b21-5256f2529a09",
   "metadata": {},
   "source": [
    "## Mask Filling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50b25b05-2576-4405-b1c0-c5bc85c9c70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af6bccb33964821929a568ca2955496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e39ce5c23ff4fc1ae660ce770718d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42373d7829084b7abcf7760d8e9b9a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29044f93a82457294b2720dfa8702ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990428d380e045beac89d1800ae6d850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7fbbe62-a0a6-40f0-a35b-628e4f1563a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1961970329284668,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052671417593956,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using distilbert/distilroberta-base\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "704ff551-c625-407e-b480-08546af264df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2596321702003479,\n",
       "  'token': 1648,\n",
       "  'token_str': 'role',\n",
       "  'sequence': 'This course will teach you all about role models.'},\n",
       " {'score': 0.09427190572023392,\n",
       "  'token': 1103,\n",
       "  'token_str': 'the',\n",
       "  'sequence': 'This course will teach you all about the models.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Google BERT base model (cased)\n",
    "unmasker(\"This course will teach you all about [MASK] models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc696c4-3d59-4a9e-9f8d-5104375c6855",
   "metadata": {},
   "source": [
    "## Named Entity Recognition \n",
    "Named entity recognition (NER) is a task where the model has to find which parts of the input text correspond to entities such as persons, locations, or organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd4249be-7dcd-4971-8e1d-dc056c106bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ba120845c54d5583c60f2c651c9349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14454474846e4e738c9cb23b8585eccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/434M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93fadf522594ae1a1f811a286d4be0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33baf693843348b7b8c2b0cebee49465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/224k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17503580eef84aac8875c95444ae5ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/695k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7697612c4ff4e5cb88bf443b0ad772d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n",
      "/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline('ner', model='eventdata-utd/conflibert-named-entity-recognition', grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "129fca9f-a911-4483-aa9f-2dcaf4adfe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9982609,\n",
       "  'word': 'Harpreet',\n",
       "  'start': 11,\n",
       "  'end': 19},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9989806,\n",
       "  'word': 'Google',\n",
       "  'start': 34,\n",
       "  'end': 40},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9986883,\n",
       "  'word': 'Bangalore',\n",
       "  'start': 44,\n",
       "  'end': 53}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using default Model\n",
    "ner(\"My name is Harpreet and I work at Google in Bangalore.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c55118-7ebc-4baa-8a70-0a90bff02fce",
   "metadata": {},
   "source": [
    "The Model correctly identified that Harpeet is a person, Google is an organization and bangalore is a location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e2d110f-4632-4669-bd9d-1b9ea900a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'Person',\n",
       "  'score': 0.97572845,\n",
       "  'word': 'my',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity_group': 'Person',\n",
       "  'score': 0.9741495,\n",
       "  'word': 'harpreet',\n",
       "  'start': 11,\n",
       "  'end': 19},\n",
       " {'entity_group': 'Person',\n",
       "  'score': 0.99614257,\n",
       "  'word': 'i',\n",
       "  'start': 24,\n",
       "  'end': 25},\n",
       " {'entity_group': 'Organisation',\n",
       "  'score': 0.9885367,\n",
       "  'word': 'google',\n",
       "  'start': 34,\n",
       "  'end': 40},\n",
       " {'entity_group': 'Location',\n",
       "  'score': 0.9990915,\n",
       "  'word': 'bangalore',\n",
       "  'start': 44,\n",
       "  'end': 53}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Using eventdata-utd/conflibert-named-entity-recognition\n",
    "ner(\"My name is Harpreet and I work at Google in Bangalore.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f24a49-8052-4213-a03d-3743cfb98169",
   "metadata": {},
   "source": [
    "## Question Answering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23468a-c712-48bf-9727-e43641c8a635",
   "metadata": {},
   "source": [
    "The question answering pipeline answers questions using information from a given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48dc40a8-301a-4fcc-8353-02ad7d4e42ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "question_answerer_default = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c921c65-aab6-4a2c-888a-d4ce2455521f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.694976270198822, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer_default(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1d181f4-97a1-4000-a258-ea0af9cfa293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.49766385555267334, 'start': 37, 'end': 48, 'answer': 'The kitchen'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer_default(\n",
    "    question='What is the bathroom south of?',\n",
    "    context='The office is south of the bathroom. The kitchen is north of the bathroom.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e5b23ff-3835-4d76-8c0a-23f16c8ab8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6194040775299072, 'start': 38, 'end': 50, 'answer': 'The bathroom'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer_default(\n",
    "    question='What is the bedroom south of?', \n",
    "    context='The kitchen is north of the bathroom. The bathroom is north of the bedroom.',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3af0b-c5f0-431c-b437-fe72d4e25dd5",
   "metadata": {},
   "source": [
    "*Note*: that this pipeline works by extracting information from the provided context; it does not generate the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580940f5-43c5-46ac-94e9-52740a62ab22",
   "metadata": {},
   "source": [
    "### Using deepset/roberta-base-squad2 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78e56691-4298-4f6c-b726-d2cc546d2bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbb6c44833f404e89cfa1cd55a79296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2dcb9c5b1b461b89844ab9f95a4e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForQuestionAnswering: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaca943198294c81b109a28a5b7b81c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9e64fbc8334eeb9d1f486c58f2f927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fb3749372b4635acb864568e86a39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b208b43f3b468f91b61ccb2b38e65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline('question-answering', model='deepset/roberta-base-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70c4867c-7c94-40dd-a878-8790d2bd5088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6549862623214722, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dea002bb-1721-4dfc-a7b9-bda2a2177db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.8777550394588616e-06, 'start': 28, 'end': 36, 'answer': 'bathroom'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question='What is the bedroom south of?', \n",
    "    context='The kitchen is north of the bathroom. The bathroom is north of the bedroom.',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415672b-f944-46c4-862d-e23c15adb5ae",
   "metadata": {},
   "source": [
    "## Summarization \n",
    "Summarization is the task of reducing a text into a shorter text while keeping all (or most) of the important aspects referenced in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e3d55a8-9b80-429a-854f-859ab25d8ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0cddd00ed3448bbf5cb4dca675feb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1184e003baf1457594597e0fc15cc09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0521afbec144639ba6c1aec0ff05fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:01<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92cb99a20a84329b78292a0e9a4fa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c857ac6df94b9cb70845e6c854990d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization', model='facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa5087bd-27b7-4c21-9897-ac4d8b8d037c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Walmart is offering a $75 discount on a pair of Apple AirPods with a Lightning charging case. The third-gen AirPod are still rock solid for routine music, podcasts, calls, and other listening needs. The charging case adds 24 hours of playtime to the earbudsâ€™ six-hour battery life.'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    If youâ€™re looking for a good opportunity to upgrade from an older pair of AirPods, \n",
    "    then some of the early Black Friday sales going on right now are where you want to be.\n",
    "    Walmart, for example, has chopped down the price of a pair of Apple AirPods (third-gen) with a\n",
    "    Lightning charging case to $94, which is a massive $75 off and easily the lowest price weâ€™ve seen to date.\n",
    "    \n",
    "    The fourth-gen AirPods are out now â€” with slight audio quality and comfort improvements, \n",
    "    plus the option to get them with active noise cancellation and a wireless charging case bearing its own speaker â€”\n",
    "    but the third-gen AirPods are still rock solid for routine music, podcasts, calls, and other listening needs.\n",
    "    The charging case adds 24 hours of playtime to the earbudsâ€™ six-hour battery life, but without the option for wireless charging,\n",
    "    the Lightning connector is a bit of a downer now that Apple has moved on from it in nearly all of its latest devices. \n",
    "    Still, the price is low enough that it may be worth keeping an extra cable handy.\n",
    "\n",
    "    And the third-gen AirPods are still great on other merits.\n",
    "    They were the first base AirPods to snub the tailpipe in an overdue design refresh,\n",
    "    but theyâ€™re also notable for adding spatial audio head tracking, IPX4 sweat and water resistance, precision \n",
    "    Find My, automatic and quick device pairing and switching, and other tight integrations with iPhones, iPads, Macs, \n",
    "    and other Apple devices. We considered them well-balanced at their original price, so theyâ€™re even easier \n",
    "    to recommend with todayâ€™s discount.\n",
    "\"\"\", max_length=150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3223d7-322e-4e0d-adf7-ddd83d99e3e6",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdd19344-daa5-4f17-9d64-e4445933131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(12843) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ef2b08-1bda-4f1b-acda-96ced0e086e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-fr-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n",
      "/opt/anaconda3/envs/transformers/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use 0\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-fr-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c0444b-cf1b-4bca-887e-9c1c04f422f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Chuck Sipes effectively used a 3-day training routine, focusing on a high volume and intensity adapted to his personal comments and goals.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Chuck Sipes a utilisÃ© efficacement une routine d'entraÃ®nement de 3 jours, mettant l'accent sur un volume et une intensitÃ© Ã©levÃ©s adaptÃ©s Ã  ses commentaires et objectifs personnels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
